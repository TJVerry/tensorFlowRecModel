{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f361281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:04:04.440678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745863444.473022    7685 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745863444.483419    7685 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745863444.505868    7685 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745863444.505918    7685 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745863444.505920    7685 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745863444.505922    7685 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 14:04:04.513735: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cbb14d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Check device that tensorflow is using\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff81f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745863451.092728    7685 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6073 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 Super with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings shape:  100000\n",
      "Movies shape:  1682\n"
     ]
    }
   ],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "# Check the data shape\n",
    "print(\"Ratings shape: \", ratings.cardinality().numpy())\n",
    "print(\"Movies shape: \", movies.cardinality().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1454ca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': np.float32(45.0),\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': np.float32(46.0),\n",
      " 'timestamp': np.int64(879024327),\n",
      " 'user_gender': np.True_,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': np.int64(4),\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': np.float32(4.0),\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:04:11.747347: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-04-28 14:04:11.773744: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-04-28 14:04:11.784514: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e60af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4]),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:04:11.902163: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-04-28 14:04:11.913916: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "015a7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4a6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae18b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:04:21.128149: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
       "       b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
       "       b'2 Days in the Valley (1996)',\n",
       "       b'20,000 Leagues Under the Sea (1954)',\n",
       "       b'2001: A Space Odyssey (1968)',\n",
       "       b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
       "       b'39 Steps, The (1935)'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34769478",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c73694",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fe7d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the movie titles are properly encoded as strings\n",
    "candidate_embeddings = movies.batch(128).map(lambda x: movie_model(tf.convert_to_tensor(x, dtype=tf.string)))\n",
    "\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=candidate_embeddings\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a59ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, movie_model):\n",
    "    super().__init__()\n",
    "    self.movie_model: tf.keras.Model = movie_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model,\n",
    "    # getting embeddings back.\n",
    "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6bddc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(user_model, movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8d11e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4925a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745863468.967881    7831 service.cc:152] XLA service 0x7f786fb56290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745863468.967951    7831 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 Super with Max-Q Design, Compute Capability 7.5\n",
      "2025-04-28 14:04:28.994467: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1745863469.068083    7831 cuda_dnn.cc:529] Loaded cuDNN version 90701\n",
      "I0000 00:00:1745863469.443837    7831 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 26s 2s/step - factorized_top_k/top_1_categorical_accuracy: 3.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0039 - factorized_top_k/top_10_categorical_accuracy: 0.0097 - factorized_top_k/top_50_categorical_accuracy: 0.0667 - factorized_top_k/top_100_categorical_accuracy: 0.1356 - loss: 69838.2138 - regularization_loss: 0.0000e+00 - total_loss: 69838.2138\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 16s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0125 - factorized_top_k/top_10_categorical_accuracy: 0.0278 - factorized_top_k/top_50_categorical_accuracy: 0.1399 - factorized_top_k/top_100_categorical_accuracy: 0.2612 - loss: 67496.5838 - regularization_loss: 0.0000e+00 - total_loss: 67496.5838\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 18s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0191 - factorized_top_k/top_10_categorical_accuracy: 0.0394 - factorized_top_k/top_50_categorical_accuracy: 0.1777 - factorized_top_k/top_100_categorical_accuracy: 0.3059 - loss: 66306.1371 - regularization_loss: 0.0000e+00 - total_loss: 66306.1371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f78d01819d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "446e86a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 10s 860ms/step - factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0078 - factorized_top_k/top_10_categorical_accuracy: 0.0194 - factorized_top_k/top_50_categorical_accuracy: 0.1214 - factorized_top_k/top_100_categorical_accuracy: 0.2359 - loss: 31093.0869 - regularization_loss: 0.0000e+00 - total_loss: 31093.0869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0008500000112690032,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.007799999788403511,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.01940000057220459,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.12144999951124191,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.23594999313354492,\n",
       " 'loss': 28263.037109375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28263.037109375}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d8c3bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'Bridges of Madison County, The (1995)'\n",
      " b\"Kid in King Arthur's Court, A (1995)\" b'Michael (1996)']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8c6face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiv40k74j/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiv40k74j/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'Bridges of Madison County, The (1995)'\n",
      " b\"Kid in King Arthur's Court, A (1995)\" b'Michael (1996)']\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "  path = os.path.join(tmp, \"model\")\n",
    "\n",
    "  # Save the index.\n",
    "  tf.saved_model.save(index, path)\n",
    "\n",
    "  # Load it back; can also be done in TensorFlow Serving.\n",
    "  loaded = tf.saved_model.load(path)\n",
    "\n",
    "  # Pass a user id in, get top predicted movie titles back.\n",
    "  scores, titles = loaded([\"42\"])\n",
    "\n",
    "  print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "524e6b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745863533.203344    7685 partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1682\n",
      "W0000 00:00:1745863533.213314    7685 gmm_utils.cc:1012] Could not normalize centroid due to zero norm or empty or zero-weight partition.\n",
      "I0000 00:00:1745863533.223599    7685 kmeans_tree_partitioner_utils.h:90] PartitionerFactory ran in 20.10905ms.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7f78a435a090>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_model)\n",
    "scann_index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc9dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'Bridges of Madison County, The (1995)'\n",
      " b\"Kid in King Arthur's Court, A (1995)\" b'It Could Happen to You (1994)']\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations.\n",
    "_, titles = scann_index(tf.constant([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10c06efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6l_9zklg/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6l_9zklg/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'Bridges of Madison County, The (1995)'\n",
      " b\"Kid in King Arthur's Court, A (1995)\" b'It Could Happen to You (1994)']\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "  path = os.path.join(tmp, \"model\")\n",
    "\n",
    "  # Save the index.\n",
    "  tf.saved_model.save(\n",
    "      scann_index,\n",
    "      path,\n",
    "      options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
    "  )\n",
    "\n",
    "  # Load it back; can also be done in TensorFlow Serving.\n",
    "  loaded = tf.saved_model.load(path)\n",
    "\n",
    "  # Pass a user id in, get top predicted movie titles back.\n",
    "  scores, titles = loaded([\"42\"])\n",
    "\n",
    "  print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de1fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
